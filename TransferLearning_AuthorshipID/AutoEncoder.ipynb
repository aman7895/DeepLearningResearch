{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import json\n",
    "import py_crepe\n",
    "import datetime\n",
    "import numpy as np\n",
    "import data_helpers\n",
    "import data\n",
    "import string\n",
    "import pandas as pd\n",
    "import autoEncoder\n",
    "np.random.seed(0123)  # for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "\n",
    "subset = None\n",
    "\n",
    "#Whether to save model parameters\n",
    "save = False\n",
    "model_name_path = 'params/crepe_model.json'\n",
    "model_weights_path = 'params/auto_model_weights.h5'\n",
    "\n",
    "#Maximum length. Longer gets chopped. Shorter gets padded.\n",
    "maxlen = 1014\n",
    "\n",
    "#Model params\n",
    "#Filters for conv layers\n",
    "nb_filter = 128 #initially 256\n",
    "#Number of units in the dense layer\n",
    "dense_outputs = 512 #Initially 1024\n",
    "#Conv layer kernel size\n",
    "filter_kernels = [7, 7, 3, 3, 3, 3]\n",
    "#Number of units in the final output layer. Number of classes.\n",
    "\n",
    "#Compile/fit params\n",
    "batch_size = 32\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 68\n",
      "author_id       int64\n",
      "doc_content    object\n",
      "dtype: object\n",
      "Data Frame created: Shape: (22208, 2)\n",
      "Author:  1416  Size: 11153\n",
      "Author:  1472  Size:  4209\n",
      "Author:  3816  Size:  6846\n",
      "Min: 4209\n",
      "Max: 11153\n",
      "Authors [1416, 1472, 3816].\n",
      "Found 12627 texts.\n",
      "Found 12627 labels.\n",
      "Creating vocab...\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "#Expect x to be a list of sentences. Y to be a one-hot encoding of the\n",
    "#categories.\n",
    "\n",
    "### 515-1122-122 and 1573 with remove 6 layers\n",
    "#authorlist=[121, 479 , 649 ]\n",
    "#doc_id = 14706\n",
    "\n",
    "authorlist=[3816, 1416, 1472]\n",
    "doc_id = [3756, 3253, 3399, 3393, 13442, 14907]\n",
    "cat_output = len(authorlist) #binary in the last layer\n",
    "\n",
    "# def main(authorlist, doc_id):\n",
    "    \n",
    "    \n",
    "((trainX, trainY), (valX, valY)) = data_helpers.load_ag_data(authors = authorlist, docID = doc_id)\n",
    "\n",
    "print('Creating vocab...')\n",
    "vocab, reverse_vocab, vocab_size, check = data_helpers.create_vocab_set()\n",
    "\n",
    "\n",
    "#trainX = data_helpers.encode_data(trainX, maxlen, vocab, vocab_size, check)\n",
    "#test_data = data_helpers.encode_data(valX, maxlen, vocab, vocab_size, check)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "classes = len(authorlist)\n",
    "(model, model_weights_path) = autoEncoder.fcc_auto_model(maxlen, vocab_size, \n",
    "                                                         model_weights_path, \n",
    "                                                         dense_outputs, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model...\n",
      "Epoch: 0\n",
      "  Step: 100\n",
      "\tLoss: 1.309247576. Accuracy: 0.336875\n",
      "  Step: 200\n",
      "\tLoss: 1.20826309919. Accuracy: 0.3275\n",
      "  Step: 300\n",
      "\tLoss: 1.17173096617. Accuracy: 0.326666666667\n",
      "Epoch 0. Loss: 1.09866905816. Accuracy: 0.323549578084\n",
      "Epoch time: 0:00:45.764792. Total time: 0:00:46.012874\n",
      "\n",
      "Epoch: 1\n",
      "  Step: 100\n",
      "\tLoss: 1.09862256289. Accuracy: 0.3284375\n",
      "  Step: 200\n",
      "\tLoss: 1.09865560412. Accuracy: 0.326875\n",
      "  Step: 300\n",
      "\tLoss: 1.0986303556. Accuracy: 0.331458333333\n",
      "Epoch 1. Loss: 1.09872667095. Accuracy: 0.323391350387\n",
      "Epoch time: 0:00:44.708508. Total time: 0:01:30.975304\n",
      "\n",
      "Epoch: 2\n",
      "  Step: 100\n",
      "\tLoss: 1.09860165715. Accuracy: 0.3409375\n",
      "  Step: 200\n",
      "\tLoss: 1.09858368993. Accuracy: 0.3409375\n",
      "  Step: 300\n",
      "\tLoss: 1.0986249272. Accuracy: 0.336979166667\n",
      "Epoch 2. Loss: 1.09873513783. Accuracy: 0.323364978916\n",
      "Epoch time: 0:00:44.799826. Total time: 0:02:16.045548\n",
      "\n",
      "Epoch: 3\n",
      "  Step: 100\n",
      "\tLoss: 1.0986535728. Accuracy: 0.328125\n",
      "  Step: 200\n",
      "\tLoss: 1.09865649998. Accuracy: 0.32765625\n",
      "  Step: 300\n",
      "\tLoss: 1.09863178611. Accuracy: 0.3315625\n",
      "Epoch 3. Loss: 1.09874935844. Accuracy: 0.323391350387\n",
      "Epoch time: 0:00:44.477191. Total time: 0:03:00.776105\n",
      "\n",
      "Epoch: 4\n",
      "  Step: 100\n",
      "\tLoss: 1.09858823419. Accuracy: 0.341875\n",
      "  Step: 200\n",
      "\tLoss: 1.09864521503. Accuracy: 0.33421875\n",
      "  Step: 300\n",
      "\tLoss: 1.09863402287. Accuracy: 0.334583333333\n",
      "Epoch 4. Loss: 1.09874805921. Accuracy: 0.323602321027\n",
      "Epoch time: 0:00:45.424471. Total time: 0:03:46.455721\n",
      "\n",
      "Epoch: 5\n",
      "  Step: 100\n",
      "\tLoss: 1.09868794441. Accuracy: 0.333125\n",
      "  Step: 200\n",
      "\tLoss: 1.09854912937. Accuracy: 0.3421875\n",
      "  Step: 300\n",
      "\tLoss: 1.09862427314. Accuracy: 0.336666666667\n",
      "Epoch 5. Loss: 1.09875236735. Accuracy: 0.323470464236\n",
      "Epoch time: 0:00:45.661601. Total time: 0:04:32.376363\n",
      "\n",
      "Epoch: 6\n",
      "  Step: 100\n",
      "\tLoss: 1.09870868802. Accuracy: 0.33\n",
      "  Step: 200\n",
      "\tLoss: 1.09867672563. Accuracy: 0.33296875\n",
      "  Step: 300\n",
      "\tLoss: 1.09864852031. Accuracy: 0.334583333333\n",
      "Epoch 6. Loss: 1.09878825085. Accuracy: 0.323444092953\n",
      "Epoch time: 0:00:46.352505. Total time: 0:05:18.983372\n",
      "\n",
      "Epoch: 7\n",
      "  Step: 100\n",
      "\tLoss: 1.09865003943. Accuracy: 0.3353125\n",
      "  Step: 200\n",
      "\tLoss: 1.09861992002. Accuracy: 0.33015625\n",
      "  Step: 300\n",
      "\tLoss: 1.09865930398. Accuracy: 0.332291666667\n",
      "Epoch 7. Loss: 1.09879555732. Accuracy: 0.32341772167\n",
      "Epoch time: 0:00:47.613797. Total time: 0:06:06.848117\n",
      "\n",
      "Epoch: 8\n",
      "  Step: 100\n",
      "\tLoss: 1.09860123396. Accuracy: 0.340625\n",
      "  Step: 200\n",
      "\tLoss: 1.0985621345. Accuracy: 0.341875\n",
      "  Step: 300\n",
      "\tLoss: 1.09862414996. Accuracy: 0.336979166667\n",
      "Epoch 8. Loss: 1.09877255898. Accuracy: 0.323444092953\n",
      "Epoch time: 0:00:46.791121. Total time: 0:06:53.913367\n",
      "\n",
      "Epoch: 9\n",
      "  Step: 100\n",
      "\tLoss: 1.09843089938. Accuracy: 0.3340625\n",
      "  Step: 200\n",
      "\tLoss: 1.09854709685. Accuracy: 0.33609375\n",
      "  Step: 300\n",
      "\tLoss: 1.09860283176. Accuracy: 0.336666666667\n",
      "Epoch 9. Loss: 1.09875003597. Accuracy: 0.323364978916\n",
      "Epoch time: 0:00:46.524396. Total time: 0:07:40.697658\n",
      "\n",
      "Epoch: 10\n",
      "  Step: 100\n",
      "\tLoss: 1.09860962033. Accuracy: 0.3346875\n",
      "  Step: 200\n",
      "\tLoss: 1.09865190744. Accuracy: 0.3290625\n",
      "  Step: 300\n",
      "\tLoss: 1.0986252745. Accuracy: 0.333125\n",
      "Epoch 10. Loss: 1.09876310674. Accuracy: 0.323338607633\n",
      "Epoch time: 0:00:46.811952. Total time: 0:08:27.762207\n",
      "\n",
      "Epoch: 11\n",
      "  Step: 100\n",
      "\tLoss: 1.09873484969. Accuracy: 0.3234375\n",
      "  Step: 200\n",
      "\tLoss: 1.09868134141. Accuracy: 0.328125\n",
      "  Step: 300\n",
      "\tLoss: 1.09863618255. Accuracy: 0.333229166667\n",
      "Epoch 11. Loss: 1.09877688824. Accuracy: 0.323496835518\n",
      "Epoch time: 0:00:46.463448. Total time: 0:09:14.488610\n",
      "\n",
      "Epoch: 12\n",
      "  Step: 100\n",
      "\tLoss: 1.09844805598. Accuracy: 0.3490625\n",
      "  Step: 200\n",
      "\tLoss: 1.09859647691. Accuracy: 0.339375\n",
      "  Step: 300\n",
      "\tLoss: 1.09862247705. Accuracy: 0.3365625\n",
      "Epoch 12. Loss: 1.09876133822. Accuracy: 0.323470464236\n",
      "Epoch time: 0:00:45.411093. Total time: 0:10:00.159409\n",
      "\n",
      "Epoch: 13\n",
      "  Step: 100\n",
      "\tLoss: 1.09838502407. Accuracy: 0.3496875\n",
      "  Step: 200\n",
      "\tLoss: 1.09856912076. Accuracy: 0.33875\n",
      "  Step: 300\n",
      "\tLoss: 1.09863598029. Accuracy: 0.335416666667\n",
      "Epoch 13. Loss: 1.09873439089. Accuracy: 0.323496835518\n",
      "Epoch time: 0:00:46.103243. Total time: 0:10:46.520727\n",
      "\n",
      "Epoch: 14\n",
      "  Step: 100\n",
      "\tLoss: 1.09863221645. Accuracy: 0.3290625\n",
      "  Step: 200\n",
      "\tLoss: 1.09861621261. Accuracy: 0.33265625\n",
      "  Step: 300\n",
      "\tLoss: 1.09861013095. Accuracy: 0.334375\n",
      "Epoch 14. Loss: 1.09873636765. Accuracy: 0.323364978916\n",
      "Epoch time: 0:00:45.295726. Total time: 0:11:32.071149\n",
      "\n",
      "Epoch: 15\n",
      "  Step: 100\n",
      "\tLoss: 1.09865458608. Accuracy: 0.3353125\n",
      "  Step: 200\n",
      "\tLoss: 1.09860212564. Accuracy: 0.33875\n",
      "  Step: 300\n",
      "\tLoss: 1.09863396605. Accuracy: 0.3365625\n",
      "Epoch 15. Loss: 1.09874774987. Accuracy: 0.32341772167\n",
      "Epoch time: 0:00:44.576109. Total time: 0:12:16.893561\n",
      "\n",
      "Epoch: 16\n",
      "  Step: 100\n",
      "\tLoss: 1.09862082958. Accuracy: 0.3378125\n",
      "  Step: 200\n",
      "\tLoss: 1.09854201853. Accuracy: 0.3409375\n",
      "  Step: 300\n",
      "\tLoss: 1.09864200592. Accuracy: 0.335104166667\n",
      "Epoch 16. Loss: 1.098740712. Accuracy: 0.323364978916\n",
      "Epoch time: 0:00:45.240897. Total time: 0:13:02.381652\n",
      "\n",
      "Epoch: 17\n",
      "  Step: 100\n",
      "\tLoss: 1.09860605121. Accuracy: 0.3365625\n",
      "  Step: 200\n",
      "\tLoss: 1.0986201036. Accuracy: 0.3334375\n",
      "  Step: 300\n",
      "\tLoss: 1.09859999736. Accuracy: 0.336875\n",
      "Epoch 17. Loss: 1.09874799885. Accuracy: 0.323496835518\n",
      "Epoch time: 0:00:44.660037. Total time: 0:13:47.290252\n",
      "\n",
      "Epoch: 18\n",
      "  Step: 100\n",
      "\tLoss: 1.09865934968. Accuracy: 0.33375\n",
      "  Step: 200\n",
      "\tLoss: 1.09865172982. Accuracy: 0.33375\n",
      "  Step: 300\n",
      "\tLoss: 1.09865594586. Accuracy: 0.333229166667\n",
      "Epoch 18. Loss: 1.09876195389. Accuracy: 0.32341772167\n",
      "Epoch time: 0:00:44.752177. Total time: 0:14:32.297281\n",
      "\n",
      "Epoch: 19\n",
      "  Step: 100\n",
      "\tLoss: 1.09865730286. Accuracy: 0.3271875\n",
      "  Step: 200\n",
      "\tLoss: 1.09855521858. Accuracy: 0.339375\n",
      "  Step: 300\n",
      "\tLoss: 1.0986081024. Accuracy: 0.3371875\n",
      "Epoch 19. Loss: 1.09875493864. Accuracy: 0.323391350387\n",
      "Epoch time: 0:00:47.369322. Total time: 0:15:19.912461\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimport cPickle as pickle\\nwith open('sgd.pickle', 'wb') as handle:\\n    pickle.dump(sgd, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Fit model...')\n",
    "initial = datetime.datetime.now()\n",
    "for e in xrange(nb_epoch):\n",
    "    xi, yi = data_helpers.shuffle_matrix(trainX, trainY)\n",
    "    xi_test, yi_test = data_helpers.shuffle_matrix(valX, valY)\n",
    "    if subset:\n",
    "        batches = data_helpers.mini_batch_generator(xi[:subset], yi[:subset],\n",
    "                                                    vocab, vocab_size, check,\n",
    "                                                    maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "    else:\n",
    "        batches = data_helpers.mini_batch_generator(xi, yi, vocab, vocab_size,\n",
    "                                                    check, maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "    test_batches = data_helpers.mini_batch_generator(xi_test, yi_test, vocab,\n",
    "                                                     vocab_size, check, maxlen,\n",
    "                                                     batch_size=batch_size)\n",
    "\n",
    "    accuracy = 0.0\n",
    "    loss = 0.0\n",
    "    step = 1\n",
    "    start = datetime.datetime.now()\n",
    "    print('Epoch: {}'.format(e))\n",
    "    for x_train, y_train in batches:\n",
    "        \n",
    "        f = model.train_on_batch(x_train, y_train)\n",
    "        loss += f[0]\n",
    "        loss_avg = loss / step\n",
    "        accuracy += f[1]\n",
    "        accuracy_avg = accuracy / step\n",
    "        if step % 100 == 0:\n",
    "            print('  Step: {}'.format(step))\n",
    "            print('\\tLoss: {}. Accuracy: {}'.format(loss_avg, accuracy_avg))\n",
    "        step += 1\n",
    "\n",
    "    test_accuracy = 0.0\n",
    "    test_loss = 0.0\n",
    "    test_step = 1\n",
    "    \n",
    "    for x_test_batch, y_test_batch in test_batches:\n",
    "        f_ev = model.test_on_batch(x_test_batch, y_test_batch)\n",
    "        test_loss += f_ev[0]\n",
    "        test_loss_avg = test_loss / test_step\n",
    "        test_accuracy += f_ev[1]\n",
    "        test_accuracy_avg = test_accuracy / test_step\n",
    "        test_step += 1\n",
    "    stop = datetime.datetime.now()\n",
    "    e_elap = stop - start\n",
    "    t_elap = stop - initial\n",
    "    print('Epoch {}. Loss: {}. Accuracy: {}\\nEpoch time: {}. Total time: {}\\n'.format(e, test_loss_avg, test_accuracy_avg, e_elap, t_elap))\n",
    "\n",
    "if save:\n",
    "    print('Saving model params...')\n",
    "    json_string = model.to_json()\n",
    "    with open(model_name_path, 'w') as f:\n",
    "        json.dump(json_string, f)\n",
    "\n",
    "model.save_weights(model_weights_path)\n",
    "\n",
    "'''\n",
    "import cPickle as pickle\n",
    "with open('sgd.pickle', 'wb') as handle:\n",
    "    pickle.dump(sgd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del trainX, trainY, valX, valY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b199749ee17e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#sgd = SGD(lr=0.01, momentum=0.9, nesterov= True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_weights(model_weights_path)\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "#sgd = SGD(lr=0.01, momentum=0.9, nesterov= True)\n",
    "\n",
    "# Compile model again (required to make predictions)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_binary = []\n",
    "for docs in doc_id:\n",
    "    (testX, testY) = data_helpers.load_doc_data(authors = authorlist, docID = docs)\n",
    "    testX = data_helpers.encode_data(testX, maxlen, vocab, vocab_size, check)\n",
    "    predY = np.array(model.predict(testX, batch_size=batch_size))\n",
    "    testY = np.array(testY)\n",
    "    predY = predY.mean(axis = 0)\n",
    "    testY = testY.mean(axis = 0)\n",
    "    predLocation = predY.tolist().index(max(predY))\n",
    "    if predLocation == testY:\n",
    "        test_binary.append(1)\n",
    "    else:\n",
    "        test_binary.append(0)\n",
    "    \n",
    "    \n",
    "    from IPython.display import clear_output\n",
    "    clear_output()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predY = np.array(model.predict(testX, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predY.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature_model = py_crepe.build_feature_model()\n",
    "feature_trainX = feature_model.predict(trainX)\n",
    "feature_testX = feature_model.predict(testX)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
